{% extends "base.html" %}
{% block content %}
<script>
$(document).ready(function () {
  $('.nav-link-docs').addClass('link-active');
});
</script>

<div class="container">

{% filter markdown %}

## Table of Contents

1. [Overview](#overview)
2. [Installation](#installation)
    1. [Boost, glog, gflags, gtest](#install-boost-glog-gflags-gtest)
    2. [Google protocol buffers](#install-google-protobuf)
    3. [Eigen](#install-eigen)
    4. [OpenCV](#install-opencv)
    5. [Tensorflow](#install-tensorflow)
    6. [Flowthrone](#install-flowthrone)
3. [Usage](#usage)
4. [Webserver](#webserver)

<br>

### Overview <a name="overview"></a>

Flowthrone is a library for dense optical flow. It can produce results like
this:

<figure>
  <a href="{{url_for('static', filename='example-in-the-loop.jpg')}}">
  <img style="max-width: 100%" src="{{ url_for('static', filename='example-in-the-loop.jpg') }}"></img>
  </a>
<figcaption>
  Malcolm Tucker pointing at things.
  <em>Left</em>: alpha blended pair of images from a video sequence.
  <em>Right</em>: dense motion displacement field.
</figcaption>
</figure>
or this:
<figure>
  <a href="{{url_for('static', filename='example-seinfeld.jpg')}}">
  <img style="max-width: 100%" src="{{ url_for('static', filename='example-seinfeld.jpg') }}"></img>
  </a>
<figcaption>
  Elaine from Seinfeld.
</figcaption>
</figure>

The current model is, roughly speaking, based on [Flownet](https://arxiv.org/abs/1504.06852),
though is much smaller.


### Installation <a name="installation"></a>

The library has a lot of dependencies, none of which are nicely packaged:

* [boost](http://www.boost.org/users/download/)
* [Glog](https://github.com/google/glog) (>=0.3.3)
* [GFlags](https://github.com/gflags/gflags)
* [Googletest](https://github.com/google/googletest)
* [Google Protocol Buffers](https://github.com/google/protobuf)
  You should use [this version](http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz) due to tensorflow compatibility issues, or at the very least it should be >= 3.4.0
* OpenCV (2.4+)
* [Eigen](http://eigen.tuxfamily.org/)
  You should use [this version](https://bitbucket.org/eigen/eigen/get/429aa5254200.tar.gz) due to tensorflow compatibility issues.
* [Tensorflow](https://www.tensorflow.org/)

There are additionally many system dependencies that you may need (e.g. `cmake`,
tensorflow wants `bazel`, `python-numpy` and `python-dev`, OpenCV wants `ffmpeg`, etc).

Installation process:

* **Boost**, **Glog**, **GFlags**, and **GTest** <a name="install-boost-glog-gflags-gtest"></a>:

    Building glog or gflags from source is not advised, [especially if you use a recent gcc](https://github.com/gflags/gflags/issues/203). Instead, do:
    
            $ sudo apt-get install libboost-system libboost-filesystem 
            $ sudo apt-get install libgflags-dev libgoogle-glog-dev libgtest-dev

* **Google Protocol Buffers** <a name="install-google-protobuf"></a>:

    Build the version from the tarball above (the version in ubuntu repositories is too old).

* **Eigen** <a name="install-eigen"></a>: 
    
    Build the version from the tarball above.

* **OpenCV** <a name="install-opencv"></a>: 

    You _might_ be able to get away with:

        $ sudo apt-get install libopencv-dev

    But if that does not work, clone version 2.4 from github and build it from source:

        $ git clone https://github.com/opencv/opencv.git && cd opencv && 
        $ git fetch origin 2.4 && git checkout 2.4
        $ cd opencv && mkdir build && cd build && cmake ..               \
           -DBUILD_EXAMPLES=OFF -DBUILD_TESTS=OFF -DBUILD_PERF_TESTS=OFF \
           && make && sudo make install


* **Tensorflow** <a name="install-tensorflow"></a>

      - Clone [tensorflow](https://github.com/tensorflow/tensorflow/tree/r1.4/) repository and checkout `r1.4`:

            $ git clone https://github.com/tensorflow/tensorflow
            $ cd tensorflow && git fetch origin r1.4 && git checkout r1.4
            $ cd tensorflow && ./configure

      - Build the tensorflow pip package:

            $ cd tensorflow && bazel build --config=opt '          \
                '--incompatible_load_argument_is_label=false '     \
                '//tensorflow/tools/pip_package:build_pip_package

      - Run `build_and_install_tensorflow.py` in the root of `flowthrone` repo.
    This script will install the tensorflow shared library on your system,
    and will make it available to cmake:

            $ python build_and_install_tensorflow.py --tf_repo /your-tf-repo/

        This step is not completely foolproof; you might have errors, and they 
    might be benign.


* **Flowthrone** <a name="install-flowthrone"></a>

    After doing all steps above, you are probably ready to build `flowthrone`.
    This is simple (assuming the steps above worked okay):
    
            $ cd flowthrone && mkdir build && cd build && cmake ..
            $ make -j
            $ make test

    This will install the default/latest tensorflow model into `build/model_*` and
    will also install the default configuration for running optical flow into
    `build/config/flowthrone.pbtxt`.

    At this stage, if everything went well, you could try running optical flow on
    a pair of images:

        $ ./optical_flow_tool --img1 /path/to/image1.jpg \
                              --img2 /path/to/image2.jpg \
                              --output /tmp/blah.jpg     \
                              --visualize                \
                              --scale 1.0                \


### Usage <a name="usage"></a>

The main binary for running optical flow on images or a video is 
`optical_flow_tool`. If you are interested in performing quantitative
evaluations, you could take a look at `evaluation_tool`.


### Webserver <a name="webserver"></a>

If you can't be arsed to type long commands on a command line, *and* if you
have been very successful at configuring opencv (so that it is able to write
images and videos -- not true for the host that you are looking at), you could
use the web interface to run optical flow on various image pairs / videos.

To do that:

        $ cd webserver; sudo pip install -r requirements.txt
        $ python server.py

Then open the browser at [http://0.0.0.0:5000](http://0.0.0.0:5000)


{% endfilter %}

</div><!-- container -->


{% endblock %}
